import sys
sys.path.append('./funsearch/')

import json
import multiprocessing
from typing import Collection, Any
import http.client
import numpy as np
from implementation import sampler

def _trim_preface_of_body(sample: str) -> str:
    """Trim the redundant descriptions/symbols/'def' declaration before the function body.
    Please see my comments in sampler.LLM (in sampler.py).
    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.

    -Example sample (function & description generated by LLM):
    -------------------------------------
    This is the optimized function ...
    def tsp_v2(...) -> ...:
        return ...
    This function aims to ...
    -------------------------------------
    -This function removes the description above the function's signature, and the function's signature.
    -The indent of the code is preserved.
    -Return of this function:
    -------------------------------------
        return ...
    This function aims to ...
    -------------------------------------
    """
    lines = sample.splitlines()
    func_body_lineno = 0
    find_def_declaration = False
    for lineno, line in enumerate(lines):
        # find the first 'def' statement in the given code
        if line[:3] == 'def':
            func_body_lineno = lineno
            find_def_declaration = True
            break
    if find_def_declaration:
        code = ''
        for line in lines[func_body_lineno + 1:]:
            code += line + '\n'
        return code
    return sample

class LLMAPI(sampler.LLM):
    def __init__(self, samples_per_prompt: int, trim=True):
        super().__init__(samples_per_prompt)
        additional_prompt = ('Complete a different and more complex Python function. '
                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'
                             'Only output the Python code, no descriptions.')
        self._additional_prompt = additional_prompt
        self._trim = trim

    def draw_samples(self, prompt: str) -> Collection[str]:
        print("draw_samples")
        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]

    def _draw_sample(self, content: str) -> str:
        prompt = '\n'.join([content, self._additional_prompt])
        while True:
            try:
                conn = http.client.HTTPSConnection("api.chatanywhere.com.cn")
                payload = json.dumps({
                    "max_tokens": 512,
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "user", "content": prompt}
                    ]
                })
                headers = {
                    'Authorization': 'Bearer sk-nPqVDTKTj11o09XwF128Cb878bEe445290CaFd8c1f3637Ad.',
                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',
                    'Content-Type': 'application/json'
                }
                conn.request("POST", "/v1/chat/completions", payload, headers)
                res = conn.getresponse()
                data = res.read().decode("utf-8")
                data = json.loads(data)
                response = data['choices'][0]['message']['content']
                if self._trim:
                    response = _trim_preface_of_body(response)
                return response
            except Exception:
                continue

from implementation import evaluator
from implementation import evaluator_accelerate
from implementation import code_manipulation

class Sandbox(evaluator.Sandbox):
    def __init__(self, verbose=False, numba_accelerate=True):
        self._verbose = verbose
        self._numba_accelerate = numba_accelerate

    def run(self, program: str, function_to_run: str, function_to_evolve: str, inputs: Any, test_input: str, timeout_seconds: int, **kwargs) -> tuple[Any, bool]:
        dataset = inputs[test_input]
        result_queue = multiprocessing.Queue()
        process = multiprocessing.Process(
            target=self._compile_and_run_function,
            args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)
        )
        process.start()
        process.join(timeout=timeout_seconds)
        if process.is_alive():
            process.terminate()
            process.join()
            results = None, False
        else:
            # results = result_queue.get_nowait() if result_queue.qsize() != 0 else (None, False)
            if not result_queue.empty():
                results = result_queue.get_nowait()
            else:
                results = None, False

        if self._verbose:
            print(f'================= Evaluated Program =================')
            program_: code_manipulation.Program = code_manipulation.text_to_program(text=program)
            func_to_evolve_: str = kwargs.get('func_to_evolve', 'priority')
            function_: code_manipulation.Function = program_.get_function(func_to_evolve_)
            function_: str = str(function_).strip('\n')
            print(f'{function_}')
            print(f'-----------------------------------------------------')
            print(f'Score: {str(results)}')
            print(f'=====================================================')
            print(f'\n\n')

        return results

    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate, result_queue):
        try:
            if numba_accelerate:
                program = evaluator_accelerate.add_numba_decorator(program=program, function_to_evolve=function_to_evolve)
            all_globals_namespace = {}
            exec(program, all_globals_namespace)
            function_to_run = all_globals_namespace[function_to_run]
            results = function_to_run(dataset)
            if not isinstance(results, (int, float)):
                result_queue.put((None, False))
                return
            result_queue.put((results, True))
        except Exception:
            result_queue.put((None, False))

specification = r'''

def compute_distance_matrix(coords):
    """Calculating the Euclidean distance matrix between cities"""
    num_cities = len(coords)
    dist_matrix = np.zeros((num_cities, num_cities))
    for i in range(num_cities):
        for j in range(i + 1, num_cities):
            dist_matrix[i, j] = dist_matrix[j, i] = np.linalg.norm(np.array(coords[i]) - np.array(coords[j]))
    return dist_matrix

def greedy_insertion(dist_matrix):
    """Greedy Insertion Algorithm (GIA)"""
    num_cities = len(dist_matrix)
    tour = [0]  # Choose the city 0 first
    unvisited = set(range(1, num_cities))

    while unvisited:
        best_city, best_pos, min_increase = None, None, float('inf')

        for city in unvisited:
            for i in range(len(tour)):
                prev_city, next_city = tour[i], tour[(i + 1) % len(tour)]
                increase = (
                    dist_matrix[prev_city, city] +
                    dist_matrix[city, next_city] -
                    dist_matrix[prev_city, next_city]
                )
                if increase < min_increase:
                    best_city, best_pos, min_increase = city, i + 1, increase

        tour.insert(best_pos, best_city)
        unvisited.remove(best_city)

    return tour

def two_opt(tour, dist_matrix):
    """2-opt local optimization"""
    improved = True
    while improved:
        improved = False
        for i in range(len(tour) - 1):
            for j in range(i + 2, len(tour) - 1):
                if j - i == 1:  # Neighboring edges cannot be exchanged
                    continue
                a, b = tour[i], tour[i + 1]
                c, d = tour[j], tour[j + 1]

                if dist_matrix[a, c] + dist_matrix[b, d] < dist_matrix[a, b] + dist_matrix[c, d]:
                    tour[i + 1:j + 1] = reversed(tour[i + 1:j + 1])
                    improved = True
    return tour

def crossover(parent1, parent2):
    """Partial Mapping Crossover (PMX Crossover) for Genetic Algorithms"""
    size = len(parent1)
    start, end = sorted(random.sample(range(size), 2))
    child = [None] * size
    child[start:end] = parent1[start:end]

    for i in range(start, end):
        if parent2[i] not in child:
            while child[i] is not None:
                i = parent2.index(parent1[i])
            child[i] = parent2[i]

    for i in range(size):
        if child[i] is None:
            child[i] = parent2[i]
    
    return child

def mutate(tour):
    """Genetic algorithms for mutation (swap mutation)"""
    a, b = random.sample(range(len(tour)), 2)
    tour[a], tour[b] = tour[b], tour[a]
    return tour

def genetic_algorithm(dist_matrix, population_size=50, generations=100):
    """Genetic Algorithm for Solving TSP"""
    num_cities = len(dist_matrix)
    population = [random.sample(range(num_cities), num_cities) for _ in range(population_size)]
    
    for _ in range(generations):
        population = sorted(population, key=lambda t: evaluate_tour(t, dist_matrix))
        new_population = population[:10]

        while len(new_population) < population_size:
            p1, p2 = random.choices(population[:20], k=2)
            child = mutate(crossover(p1, p2))
            new_population.append(child)

        population = new_population
    
    return population[0]

def evaluate_tour(tour, dist_matrix):
    """Calculate the total length of the path"""
    tour_length = sum(dist_matrix[tour[i], tour[i + 1]] for i in range(len(tour) - 1)) + dist_matrix[tour[-1], tour[0]]
    print(f"Tour Length: {tour_length}")
    return tour_length

@funsearch.run
def evaluate(instances: dict) -> float:
    """Evaluating the performance of different TSP solving methods"""
    total_distance = 0
    for name, instance in instances.items():
        try:
            coords = instance['coords']
            dist_matrix = compute_distance_matrix(coords)

            # 1. Construct initial solutions using greedy insertion
            tour = greedy_insertion(dist_matrix)
            print(f"Greedy Insertion Tour: {tour}")
            # 2. local optimization with 2-opt
            tour = two_opt(tour, dist_matrix)
            print(f"2-opt Tour: {tour}")
            # 3. Further optimization with genetic algorithms
            tour = genetic_algorithm(dist_matrix)
            print(f"Genetic Algorithm Tour: {tour}")
            
            total_distance += evaluate_tour(tour, dist_matrix)
        except Exception as e:
            print(f"Error processing instance {name}: {e}")
            continue

    return -total_distance  # A negative sign indicates minimization
print(evaluate(tsp_instances)) 

@funsearch.evolve
def priority(current_city: int, unvisited: list, dist_matrix: np.ndarray) -> np.ndarray:
    """Calculate the priority of the visit to the next city"""
    distances = np.array([dist_matrix[current_city, city] for city in unvisited])
    priorities = -distances  # Negative values indicate higher priority the closer you are to the current city
    return priorities
'''

import tsp_utils

tsp_instances = {'ATT48': tsp_utils.datasets["ATT48"]}
# print(f"TSP Instances: {tsp_instances}")

from implementation import funsearch
from implementation import config

if __name__ == '__main__':
    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)
    funsearch_config = config.Config(samples_per_prompt=4, evaluate_timeout_seconds=30)
    global_max_sample_num = 10
    funsearch.main(
        specification=specification,
        inputs=tsp_instances,
        config=funsearch_config,
        max_sample_nums=global_max_sample_num,
        class_config=class_config,
        log_dir='./logs/funsearch_tsp'
    )
